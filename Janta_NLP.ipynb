{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis for Steam Reviews\n",
    "Steam is a video game digital distribution service with a vast community of gamers globally. A lot of gamers write reviews at the game page and have an option of choosing whether they would recommend this game to others or not. However, determining this sentiment automatically from text can help Steam to automatically tag such reviews extracted from other forums across the internet and can help them better judge the popularity of games.\n",
    "\n",
    "Given the review text with user recommendation and other information related to each game for 64 game titles, the task is to predict whether the reviewer recommended the game titles available in the test set on the basis of review text and other information.\n",
    "\n",
    "Game overview information for both train and test are available in single file game_overview.csv inside train.zip\n",
    "\n",
    "\n",
    "\n",
    "About Data Source:\n",
    "Steam Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#<font color='blue'>**Import Necessary Libraries**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "NLTK: 3.4.5\n",
      "Scikit-learn: 0.21.3\n",
      "Pandas: 0.25.1\n",
      "Numpy: 1.16.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\" color='blue'>Load DataSet</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset of SMS messages\n",
    "df = pd.read_csv(\"train_janta.csv\")\n",
    "game=pd.read_csv(\"game_overview.csv\")\n",
    "test=pd.read_csv(\"test_janta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17494 entries, 0 to 17493\n",
      "Data columns (total 5 columns):\n",
      "review_id          17494 non-null int64\n",
      "title              17494 non-null object\n",
      "year               17316 non-null float64\n",
      "user_review        17494 non-null object\n",
      "user_suggestion    17494 non-null int64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 683.5+ KB\n",
      "None\n",
      "   review_id                        title    year  \\\n",
      "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
      "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
      "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
      "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
      "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
      "\n",
      "                                         user_review  user_suggestion  \n",
      "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
      "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
      "2  A littly iffy on the controls, but once you kn...                1  \n",
      "3  Great game, fun and colorful and all that.A si...                1  \n",
      "4  Not many games have the cute tag right next to...                1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print useful information about the dataset\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 5 columns):\n",
      "title        64 non-null object\n",
      "developer    64 non-null object\n",
      "publisher    64 non-null object\n",
      "tags         64 non-null object\n",
      "overview     64 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.6+ KB\n",
      "None\n",
      "                              title                          developer  \\\n",
      "0       Spooky's Jump Scare Mansion                       Lag Studios    \n",
      "1                    Sakura Clicker                      Winged Cloud    \n",
      "2                           WARMODE                           WARTEAM    \n",
      "3                   Fractured Space              Edge Case Games Ltd.    \n",
      "4  Counter-Strike: Global Offensive  Valve, Hidden Path Entertainment    \n",
      "\n",
      "               publisher                                               tags  \\\n",
      "0           Lag Studios   ['Horror', 'Free to Play', 'Cute', 'First-Pers...   \n",
      "1          Winged Cloud   ['Nudity', 'Anime', 'Free to Play', 'Mature', ...   \n",
      "2               WARTEAM   ['Early Access', 'Free to Play', 'FPS', 'Multi...   \n",
      "3  Edge Case Games Ltd.   ['Space', 'Multiplayer', 'Free to Play', 'PvP'...   \n",
      "4                 Valve   ['FPS', 'Multiplayer', 'Shooter', 'Action', 'T...   \n",
      "\n",
      "                                            overview  \n",
      "0  Can you survive 1000 rooms of cute terror? Or ...  \n",
      "1  The latest entry in the Sakura series is more ...  \n",
      "2  Free to play shooter about the confrontation o...  \n",
      "3  Take the helm of a gigantic capital ship and g...  \n",
      "4  Counter-Strike: Global Offensive (CS: GO) expa...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print useful information about the dataset\n",
    "print(game.info())\n",
    "print(game.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8045 entries, 0 to 8044\n",
      "Data columns (total 4 columns):\n",
      "review_id      8045 non-null int64\n",
      "title          8045 non-null object\n",
      "year           7978 non-null float64\n",
      "user_review    8045 non-null object\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 251.5+ KB\n",
      "None\n",
      "   review_id                             title    year  \\\n",
      "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
      "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
      "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
      "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
      "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
      "\n",
      "                                         user_review  \n",
      "0  Nice graphics, new maps, weapons and models. B...  \n",
      "1  I would not recommend getting into this at its...  \n",
      "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
      "3  The game is great. But the community is the wo...  \n",
      "4  I thank TrulyRazor for buying this for me a lo...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print useful information about the dataset\n",
    "print(test.info())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    9968\n",
      "0    7526\n",
      "Name: user_suggestion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check usersuggestion distribution\n",
    "classes = df['user_suggestion']\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 5)\n",
      "(64, 5)\n",
      "(8045, 4)\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "print(df.shape)\n",
    "print(game.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>A littly iffy on the controls, but once you kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Great game, fun and colorful and all that.A si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Not many games have the cute tag right next to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
       "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
       "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
       "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
       "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
       "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
       "2  A littly iffy on the controls, but once you kn...                1  \n",
       "3  Great game, fun and colorful and all that.A si...                1  \n",
       "4  Not many games have the cute tag right next to...                1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xada1959508>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['user_suggestion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robocraft                                             842\n",
       "Eternal Card Game                                     791\n",
       "Heroes & Generals                                     745\n",
       "War Thunder                                           720\n",
       "Fractured Space                                       718\n",
       "Bless Online                                          712\n",
       "The Elder Scrolls®: Legends™                          565\n",
       "Neverwinter                                           546\n",
       "AdventureQuest 3D                                     519\n",
       "theHunter Classic                                     518\n",
       "Creativerse                                           492\n",
       "DCS World Steam Edition                               488\n",
       "Team Fortress 2                                       479\n",
       "Infestation: The New Z                                479\n",
       "PlanetSide 2                                          472\n",
       "Path of Exile                                         458\n",
       "SMITE®                                                454\n",
       "Fallout Shelter                                       447\n",
       "Realm Royale                                          442\n",
       "Trove                                                 430\n",
       "Ring of Elysium                                       419\n",
       "RaceRoom Racing Experience                            416\n",
       "Brawlhalla                                            410\n",
       "Dota 2                                                405\n",
       "Yu-Gi-Oh! Duel Links                                  399\n",
       "Cuisine Royale                                        399\n",
       "Spooky's Jump Scare Mansion                           362\n",
       "Elsword                                               342\n",
       "Realm of the Mad God                                  340\n",
       "World of Tanks Blitz                                  327\n",
       "WARMODE                                               300\n",
       "World of Guns: Gun Disassembly                        293\n",
       "Black Squad                                           288\n",
       "School of Dragons                                     268\n",
       "Bloons TD Battles                                     233\n",
       "Sakura Clicker                                        222\n",
       "Business Tour - Board Game with Online Multiplayer    191\n",
       "Realm Grinder                                         155\n",
       "Crusaders of the Lost Idols                           132\n",
       "EverQuest II                                           69\n",
       "Dreadnought                                            60\n",
       "Freestyle 2: Street Basketball                         57\n",
       "Shop Heroes                                            52\n",
       "Tactical Monsters Rumble Arena                         38\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking title distributions\n",
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018.0    4822\n",
       "2016.0    4226\n",
       "2017.0    3890\n",
       "2015.0    2460\n",
       "2014.0    1499\n",
       "2013.0     340\n",
       "2012.0      65\n",
       "2011.0      14\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking year distributions\n",
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>Lag Studios</td>\n",
       "      <td>Lag Studios</td>\n",
       "      <td>['Horror', 'Free to Play', 'Cute', 'First-Pers...</td>\n",
       "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sakura Clicker</td>\n",
       "      <td>Winged Cloud</td>\n",
       "      <td>Winged Cloud</td>\n",
       "      <td>['Nudity', 'Anime', 'Free to Play', 'Mature', ...</td>\n",
       "      <td>The latest entry in the Sakura series is more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WARMODE</td>\n",
       "      <td>WARTEAM</td>\n",
       "      <td>WARTEAM</td>\n",
       "      <td>['Early Access', 'Free to Play', 'FPS', 'Multi...</td>\n",
       "      <td>Free to play shooter about the confrontation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fractured Space</td>\n",
       "      <td>Edge Case Games Ltd.</td>\n",
       "      <td>Edge Case Games Ltd.</td>\n",
       "      <td>['Space', 'Multiplayer', 'Free to Play', 'PvP'...</td>\n",
       "      <td>Take the helm of a gigantic capital ship and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>Valve, Hidden Path Entertainment</td>\n",
       "      <td>Valve</td>\n",
       "      <td>['FPS', 'Multiplayer', 'Shooter', 'Action', 'T...</td>\n",
       "      <td>Counter-Strike: Global Offensive (CS: GO) expa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title                          developer  \\\n",
       "0       Spooky's Jump Scare Mansion                       Lag Studios    \n",
       "1                    Sakura Clicker                      Winged Cloud    \n",
       "2                           WARMODE                           WARTEAM    \n",
       "3                   Fractured Space              Edge Case Games Ltd.    \n",
       "4  Counter-Strike: Global Offensive  Valve, Hidden Path Entertainment    \n",
       "\n",
       "               publisher                                               tags  \\\n",
       "0           Lag Studios   ['Horror', 'Free to Play', 'Cute', 'First-Pers...   \n",
       "1          Winged Cloud   ['Nudity', 'Anime', 'Free to Play', 'Mature', ...   \n",
       "2               WARTEAM   ['Early Access', 'Free to Play', 'FPS', 'Multi...   \n",
       "3  Edge Case Games Ltd.   ['Space', 'Multiplayer', 'Free to Play', 'PvP'...   \n",
       "4                 Valve   ['FPS', 'Multiplayer', 'Shooter', 'Action', 'T...   \n",
       "\n",
       "                                            overview  \n",
       "0  Can you survive 1000 rooms of cute terror? Or ...  \n",
       "1  The latest entry in the Sakura series is more ...  \n",
       "2  Free to play shooter about the confrontation o...  \n",
       "3  Take the helm of a gigantic capital ship and g...  \n",
       "4  Counter-Strike: Global Offensive (CS: GO) expa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bless Online                        1\n",
       "Fishing Planet                      1\n",
       "Spooky's Jump Scare Mansion         1\n",
       "Counter-Strike: Global Offensive    1\n",
       "Tactical Monsters Rumble Arena      1\n",
       "                                   ..\n",
       "World of Guns: Gun Disassembly      1\n",
       "H1Z1                                1\n",
       "Heroes & Generals                   1\n",
       "The Elder Scrolls®: Legends™        1\n",
       "Neverwinter                         1\n",
       "Name: title, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1603</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Nice graphics, new maps, weapons and models. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>I would not recommend getting into this at its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1605</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Edit 11/12/18I have tried playing CS:GO recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1606</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>The game is great. But the community is the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1607</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>I thank TrulyRazor for buying this for me a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                             title    year  \\\n",
       "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
       "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
       "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
       "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
       "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
       "\n",
       "                                         user_review  \n",
       "0  Nice graphics, new maps, weapons and models. B...  \n",
       "1  I would not recommend getting into this at its...  \n",
       "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
       "3  The game is great. But the community is the wo...  \n",
       "4  I thank TrulyRazor for buying this for me a lo...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Magic Duels                         893\n",
       "Tree of Savior (English Ver.)       635\n",
       "Star Trek Online                    566\n",
       "Dungeon Defenders II                554\n",
       "Paladins®                           529\n",
       "Fishing Planet                      498\n",
       "Counter-Strike: Global Offensive    463\n",
       "Shadowverse CCG                     450\n",
       "The Lord of the Rings Online™       439\n",
       "H1Z1                                425\n",
       "Minion Masters                      401\n",
       "Champions Online                    383\n",
       "World of Warships                   366\n",
       "Crush Crush                         333\n",
       "Aura Kingdom                        324\n",
       "Digimon Masters Online              310\n",
       "VEGA Conflict                       173\n",
       "Shakes and Fidget                   137\n",
       "Governor of Poker 3                  89\n",
       "GUNS UP!                             77\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robocraft                                             842\n",
       "Eternal Card Game                                     791\n",
       "Heroes & Generals                                     745\n",
       "War Thunder                                           720\n",
       "Fractured Space                                       718\n",
       "Bless Online                                          712\n",
       "The Elder Scrolls®: Legends™                          565\n",
       "Neverwinter                                           546\n",
       "AdventureQuest 3D                                     519\n",
       "theHunter Classic                                     518\n",
       "Creativerse                                           492\n",
       "DCS World Steam Edition                               488\n",
       "Team Fortress 2                                       479\n",
       "Infestation: The New Z                                479\n",
       "PlanetSide 2                                          472\n",
       "Path of Exile                                         458\n",
       "SMITE®                                                454\n",
       "Fallout Shelter                                       447\n",
       "Realm Royale                                          442\n",
       "Trove                                                 430\n",
       "Ring of Elysium                                       419\n",
       "RaceRoom Racing Experience                            416\n",
       "Brawlhalla                                            410\n",
       "Dota 2                                                405\n",
       "Yu-Gi-Oh! Duel Links                                  399\n",
       "Cuisine Royale                                        399\n",
       "Spooky's Jump Scare Mansion                           362\n",
       "Elsword                                               342\n",
       "Realm of the Mad God                                  340\n",
       "World of Tanks Blitz                                  327\n",
       "WARMODE                                               300\n",
       "World of Guns: Gun Disassembly                        293\n",
       "Black Squad                                           288\n",
       "School of Dragons                                     268\n",
       "Bloons TD Battles                                     233\n",
       "Sakura Clicker                                        222\n",
       "Business Tour - Board Game with Online Multiplayer    191\n",
       "Realm Grinder                                         155\n",
       "Crusaders of the Lost Idols                           132\n",
       "EverQuest II                                           69\n",
       "Dreadnought                                            60\n",
       "Freestyle 2: Street Basketball                         57\n",
       "Shop Heroes                                            52\n",
       "Tactical Monsters Rumble Arena                         38\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_keyword=df['title'].value_counts()\n",
    "dist_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with missing location 0\n"
     ]
    }
   ],
   "source": [
    "bool_series_location = pd.isnull(df['title']) \n",
    "\n",
    "# filtering data  \n",
    "# displaying data only with location = NaN  \n",
    "df[bool_series_location]\n",
    "print(\"Number of records with missing location\",len(df[bool_series_location]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with missing location 0\n"
     ]
    }
   ],
   "source": [
    "bool_series_location = pd.isnull(df['user_review']) \n",
    "\n",
    "# filtering data  \n",
    "# displaying data only with location = NaN  \n",
    "df[bool_series_location]\n",
    "print(\"Number of records with missing location\",len(df[bool_series_location]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with missing location 178\n"
     ]
    }
   ],
   "source": [
    "bool_series_location = pd.isnull(df['year']) \n",
    "\n",
    "# filtering data  \n",
    "# displaying data only with location = NaN  \n",
    "df[bool_series_location]\n",
    "print(\"Number of records with missing location\",len(df[bool_series_location]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year does not play a role in User suggestion and there are missing values so we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y=df['user_suggestion']\n",
    "X=df['user_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30 , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction in NLP\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "Features= count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12245, 44382)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a model\n",
    "from sklearn import svm\n",
    "model=svm.SVC(kernel='linear',C=10,gamma='auto')\n",
    "model.fit(Features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_test=count_vect.transform(X_test)\n",
    "Feature_testa=count_vect.transform(test['user_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5249, 44382)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8045, 44382)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature_testa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.8146313583539722\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model\",model.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Predictions=model.predict(Feature_testa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_suggestion=pd.DataFrame(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8045 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     1\n",
       "...  ..\n",
       "8040  1\n",
       "8041  0\n",
       "8042  1\n",
       "8043  1\n",
       "8044  1\n",
       "\n",
       "[8045 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final=test['review_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final=pd.concat([test['review_id'],user_suggestion],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final.columns=['review_id','user_suggestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4597\n",
       "0    3448\n",
       "Name: user_suggestion, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final['user_suggestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final.to_csv('Submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=3000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=27, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=27, subsample=0.85,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=3000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.85,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "model.fit(Features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(Feature_testa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.855210516288817\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model\",model.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_suggestion=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final=test['review_id']\n",
    "Final=pd.concat([test['review_id'],user_suggestion],axis=1)\n",
    "Final.columns=['review_id','user_suggestion']\n",
    "Final.to_csv('Submission_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['user_suggestion']\n",
    "X_pro=df['user_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
    "\n",
    "# Replace email addresses with 'email'\n",
    "processed = X.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        i m scared and hearing creepy voices so i ll p...\n",
      "1        best game more better than sam pepper s youtub...\n",
      "2        a littly iffy on the controls but once you kno...\n",
      "3        great game fun and colorful and all that a sid...\n",
      "4        not many games have the cute tag right next to...\n",
      "                               ...                        \n",
      "17489    arguably the single greatest mmorp that exists...\n",
      "17490    an older game to be sure but has its own charm...\n",
      "17491    when i frist started playing everquest numbr i...\n",
      "17492    cool game the only thing that really pisses me...\n",
      "17493    this game since i was a little kid always have...\n",
      "Name: user_review, Length: 17494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# change words to lower case - Hello, HELLO, hello are all the same word\n",
    "processed = processed.str.lower()\n",
    "print(processed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed, Y, test_size=0.30 , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction in NLP\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "Featureset= count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12245, 42632)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Featureset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featureset_test=count_vect.fit_transform(test['user_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8045, 34285)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Featureset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featuresseta= count_vect.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5249, 25973)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Featuresseta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a model\n",
    "from sklearn import svm\n",
    "models=svm.SVC()\n",
    "models.fit(Featureset,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_suggestions=pd.DataFrame(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finall=test['review_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finall=pd.concat([test['review_id'],user_suggestions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finall.columns=['review_id','user_suggestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finall['user_suggestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of model\",model.score(Featureset_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Approach : Use K Fold Cross validation\n",
    "Manually try suppling models with different parameters to cross_val_score function with 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80971825, 0.81339322, 0.80890159, 0.81461821, 0.79828501])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cross_val_score(svm.SVC(kernel='linear',C=10,gamma='auto'),Features,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72886893, 0.72601062, 0.71376072, 0.72192732, 0.71335239])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf',C=10,gamma='auto'),Features,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7762352 , 0.7721519 , 0.77705186, 0.7680686 , 0.76970192])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf',C=20,gamma='auto'),Features,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Approach 3: Use GridSearchSV\n",
    "GridSearchCV does exactly same thing as for loop above but in a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.807350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.808983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      20       linear         0.807350\n",
       "1      10       linear         0.808983"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "        'C': [1,10,20],\n",
    "        'kernel': ['rbf','linear']\n",
    "    }, \n",
    "    cv=5, \n",
    "    return_train_score=False, \n",
    "    n_iter=2\n",
    ")\n",
    "rs.fit(Features,y_train)\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>{'kernel': 'linear', 'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.727072</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.839608</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                   best_params\n",
       "0                  svm    0.816742  {'kernel': 'linear', 'C': 1}\n",
       "1        random_forest    0.727072          {'n_estimators': 10}\n",
       "2  logistic_regression    0.839608                      {'C': 1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    rs = RandomizedSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    rs.fit(Features,y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': rs.best_score_,\n",
    "        'best_params': rs.best_params_\n",
    "    })\n",
    "    \n",
    "dfa = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here i can see logistic regression is having a score near to 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets try ensemble methods to increase performance\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(Features,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = dt.predict(Feature_testa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.8294913316822252\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model\",model.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=0.5, n_estimators=20, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), max_samples= 0.5, max_features = 1.0, n_estimators = 20)\n",
    "bg.fit(Features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.7527148028195847\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = bg.predict(Feature_testa)\n",
    "print(\"Accuracy of model\",bg.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1, n_estimators=5, random_state=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Boosting - Ada Boost\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5, learning_rate = 1)\n",
    "adb.fit(Features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.6963231091636503\n"
     ]
    }
   ],
   "source": [
    "y_pred = adb.predict(Feature_testa)\n",
    "print(\"Accuracy of model\",adb.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier - Multiple Model Ensemble \n",
    "from sklearn import svm\n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evc = VotingClassifier( estimators= [('lr',lr),('dt',dt)], voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc.fit(Features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.7550009525623929\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model\",evc.score(Feature_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
